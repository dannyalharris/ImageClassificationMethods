{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-362292f89e8b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mminkowski\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmy_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'*\\ImageClassificationMethods\\feature\\feature.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmy_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imutils'"
     ]
    }
   ],
   "source": [
    "from imutils import paths\n",
    "from scipy.spatial.distance import minkowski\n",
    "\n",
    "my_data = pd.read_csv('*\\ImageClassificationMethods\\feature\\feature.csv')\n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_val = my_data.drop('labels', axis=1)\n",
    "labels = my_data.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135176.3583782622"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate distance between two points\n",
    "\n",
    "def minkowski_distance(a, b, p=1):\n",
    "    # Store the number of dimensions\n",
    "    dim = len(a)\n",
    "    # Set initial distance to 0\n",
    "    distance = 0\n",
    "    # Calculate minkowski distance using parameter p\n",
    "    for d in range(dim):\n",
    "        distance += abs(a[d] - b[d])**p\n",
    "    distance = distance**(1/p)\n",
    "    return distance\n",
    "\n",
    "\n",
    "# Test the function\n",
    "\n",
    "minkowski_distance(a=data_val.iloc[0], b=data_val.iloc[1], p=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Split the data - 75% train, 25% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_val, labels, test_size=0.15,\n",
    "                                                   random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the X data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def knn_predict(X_train, X_test, y_train, y_test, k, p):\n",
    "\n",
    "    # Counter to help with label voting\n",
    "    from collections import Counter\n",
    "\n",
    "    # Make predictions on the test data\n",
    "    # Need output of 1 prediction per test data point\n",
    "    y_hat_test = []\n",
    "\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "\n",
    "        for train_point in X_train:\n",
    "            distance = minkowski(test_point, train_point, p)\n",
    "            # distance = minkowski_distance(test_point, train_point, p=p)\n",
    "            distances.append(distance)\n",
    "\n",
    "        # Store distances in a dataframe\n",
    "        df_dists = pd.DataFrame(data=distances, columns=['dist'],\n",
    "                                index=y_train.index)\n",
    "\n",
    "        # Sort distances, and only consider the k closest points\n",
    "        df_nn = df_dists.sort_values(by=['dist'], axis=0)[:k]\n",
    "\n",
    "        # Create counter object to track the labels of k closest neighbors\n",
    "        counter = Counter(y_train[df_nn.index])\n",
    "\n",
    "        # Get most common label of all the nearest neighbors\n",
    "        prediction = counter.most_common()[0][0]\n",
    "\n",
    "        # Append prediction to output list\n",
    "        y_hat_test.append(prediction)\n",
    "\n",
    "    return y_hat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "y_hat_test = knn_predict(X_train, X_test, y_train, y_test, k=5, p=1)\n",
    "\n",
    "print(y_hat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8166666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       brush       0.78      0.88      0.83        60\n",
      "        comb       0.87      0.75      0.80        60\n",
      "\n",
      "    accuracy                           0.82       120\n",
      "   macro avg       0.82      0.82      0.82       120\n",
      "weighted avg       0.82      0.82      0.82       120\n",
      "\n",
      "[[53  7]\n",
      " [15 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "print(accuracy_score(y_test, y_hat_test))\n",
    "print(classification_report(y_test, y_hat_test, target_names=[\"brush\", \"comb\"]))\n",
    "print(confusion_matrix(y_test, y_hat_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from preprocessing import ImageResizer\n",
    "from preprocessing import  SimpleDatasetLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "args = {\n",
    "\t\"dataset\": \"resources\",\n",
    "\t\"neighbors\": 5,\n",
    "\t\"jobs\": -1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n",
      "[INFO] processed 500/800\n",
      "[INFO] features matrix: 2.3MB\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(args[\"dataset\"]))\n",
    "\n",
    "# initialize the image preprocessor, load the dataset from disk,\n",
    "# and reshape the data matrix\n",
    "sp = ImageResizer(32, 32)\n",
    "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
    "(data, lbls) = sdl.load(imagePaths, verbose=500)\n",
    "data = data.reshape((data.shape[0], 3072))\n",
    "\n",
    "# show some information on memory consumption of the images\n",
    "print(\"[INFO] features matrix: {:.1f}MB\".format(\n",
    "\tdata.nbytes / (1024 * 1024.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Brush' 'Comb']\n"
     ]
    }
   ],
   "source": [
    "# encode the labels as integers\n",
    "le = LabelEncoder()\n",
    "lbls = le.fit_transform(lbls)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# partition the data into training and testing splits using 75% of\n",
    "# the data for training and the remaining 25% for testing\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, lbls, test_size=0.10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainY = pd.Series(data=trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Scale the X data\n",
    "scaler = StandardScaler()\n",
    "trainX = scaler.fit_transform(trainX)\n",
    "testX = scaler.transform(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "prediction_2 = knn_predict(trainX, testX, trainY, testY, k=5, p=1)\n",
    "print(prediction_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       brush       0.80      0.80      0.80        41\n",
      "        comb       0.79      0.79      0.79        39\n",
      "\n",
      "    accuracy                           0.80        80\n",
      "   macro avg       0.80      0.80      0.80        80\n",
      "weighted avg       0.80      0.80      0.80        80\n",
      "\n",
      "[[33  8]\n",
      " [ 8 31]]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(testY, prediction_2))\n",
    "print(classification_report(testY, prediction_2, target_names=[\"brush\", \"comb\"]))\n",
    "print(confusion_matrix(testY, prediction_2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
